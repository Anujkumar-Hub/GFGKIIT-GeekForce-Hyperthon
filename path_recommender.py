# -*- coding: utf-8 -*-
"""path.recommender.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l6lpxGr91LJUaQibj2FGSRY-IJGvaFbY

upload the dataset here
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
data = pd.read_csv('your.path.dataset.csv')
print(data.head())

!pip install pandas scikit-learn flask flask-cors flask-ngrok joblib

print(data.columns)

!pip install pyngrok

!ngrok config add-authtoken 2qDnXIT4dUgkWQWVFSyYY0R0JSh_7wZDTm7JaCyCJv7cELtV4

from google.colab import files

# Download the model file
files.download('career_path_model.pkl')

# Download the vectorizer file
files.download('vectorizer.pkl')

pip install flask-cors

# Install required libraries
!pip install pandas scikit-learn flask flask-cors flask-ngrok joblib

# Import libraries
import pandas as pd
import joblib
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Load the dataset
data = pd.read_csv('your.path.dataset.csv')  # Replace 'your_dataset.csv' with your actual file name

# Verify dataset structure
print("Dataset Columns:", data.columns)
print(data.head())

# Rename columns to ensure consistency (if required)
data.rename(columns={'Skills': 'skills', 'Interests': 'interests'}, inplace=True)

# Check for required columns
if 'skills' not in data.columns or 'interests' not in data.columns:
    raise KeyError("Dataset must contain 'skills' and 'interests' columns.")

# Combine skills and interests for model training
data['Combined'] = data['skills'] + " " + data['interests']

# Define input features and target variable
X = data['Combined']  # Combined features
y = data['Recommended_Career']    # Replace 'Recommended_Career' with the actual column name containing target labels

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorize the input data
vectorizer = CountVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

# Train the model
model = LogisticRegression()
model.fit(X_train_vectorized, y_train)

# Evaluate the model
y_pred = model.predict(X_test_vectorized)
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy * 100:.2f}%")

# Save the model and vectorizer
joblib.dump(model, 'career_path_model.pkl')
joblib.dump(vectorizer, 'vectorizer.pkl')
print("Model and vectorizer saved successfully!")

# Flask application
from flask import Flask, request, jsonify
from flask_cors import CORS
from pyngrok import ngrok

# Load the saved model and vectorizer
model = joblib.load('career_path_model.pkl')
vectorizer = joblib.load('vectorizer.pkl')

# Create Flask app
app = Flask(__name__)
CORS(app)

@app.route('/predict', methods=['POST'])
def predict():
    # Parse JSON request
    data = request.json
    skills = data.get('skills', [])
    interests = data.get('interests', [])

    # Validate input
    if not skills or not interests:
        return jsonify({"error": "Both 'skills' and 'interests' must be provided"}), 400

    # Combine inputs and transform
    combined_features = " ".join(skills) + " " + " ".join(interests)
    input_vectorized = vectorizer.transform([combined_features])

    # Predict
    prediction = model.predict(input_vectorized)[0]
    return jsonify({'Recommended Career': prediction})

if __name__ == '__main__':
    # Start ngrok tunnel
    public_url = ngrok.connect(5000)
    print(f"Public URL: {public_url}")

    # Run the Flask app
    app.run(port=5000)

